{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8385cdb2-d8a2-4bbe-9a41-99af85930c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adma224/anaconda3/envs/ml-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import transformers\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8920a22-47c9-4f9a-ab94-2c3df9bfbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Set device ONCE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ Memory optimizations (move these up)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.set_per_process_memory_fraction(0.6, device=0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Limit GPU & CPU usage\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Limit CPU threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb21099-2769-4592-9941-656f28ab8626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/cleaned_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb4ed7e-3ed0-4db2-8806-79d3c5a9da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline\n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1       American Airlines Flyer Charged, Banned For Li...\n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "3       The Funniest Tweets From Parents This Week (Se...\n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...\n",
       "...                                                   ...\n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...\n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...\n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...\n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...\n",
       "\n",
       "[207996 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3c30db-a4f2-4b68-9533-3bad9d61f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"headline\"]).copy()  # Remove rows where 'headline' is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa1208c-2487-4ed9-833a-7d91cdb8244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have padding by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c887ae-60ab-4a55-aec6-2660bc04d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"tokenized\"] = df[\"headline\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "max_length = max(len(tokens) for tokens in df[\"tokenized\"])\n",
    "\n",
    "df.loc[:, \"padded\"] = df[\"tokenized\"].apply(lambda x: x + [tokenizer.pad_token_id] * (max_length - len(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0065bb00-bb7d-44ad-90bf-2566aa67ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121815</th>\n",
       "      <td>Celebrities Emerging From Water Because Hey .....</td>\n",
       "      <td>[42741, 65, 19491, 48297, 3574, 5638, 4362, 14...</td>\n",
       "      <td>[42741, 65, 19491, 48297, 3574, 5638, 4362, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76633</th>\n",
       "      <td>Bill Maher Slams The Internet For Killing The ...</td>\n",
       "      <td>[17798, 38137, 30382, 82, 383, 4455, 1114, 255...</td>\n",
       "      <td>[17798, 38137, 30382, 82, 383, 4455, 1114, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188697</th>\n",
       "      <td>The Most Expensive NFL Tickets Of The Season: ...</td>\n",
       "      <td>[464, 4042, 5518, 2021, 5134, 26878, 3226, 383...</td>\n",
       "      <td>[464, 4042, 5518, 2021, 5134, 26878, 3226, 383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80361</th>\n",
       "      <td>Students Surprise Starbucks Employee With Gene...</td>\n",
       "      <td>[28239, 47893, 24527, 36824, 2080, 2980, 516, ...</td>\n",
       "      <td>[28239, 47893, 24527, 36824, 2080, 2980, 516, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65636</th>\n",
       "      <td>Ben Stein: 'I Don't Think Trump Knows A Goddam...</td>\n",
       "      <td>[11696, 15215, 25, 705, 40, 2094, 470, 11382, ...</td>\n",
       "      <td>[11696, 15215, 25, 705, 40, 2094, 470, 11382, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43356</th>\n",
       "      <td>Trump's \"Extreme Vetting\" Of Refugees Empowers...</td>\n",
       "      <td>[6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...</td>\n",
       "      <td>[6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113206</th>\n",
       "      <td>For $6 You Can Give a Coffee Tree and Help Emp...</td>\n",
       "      <td>[1890, 720, 21, 921, 1680, 13786, 257, 19443, ...</td>\n",
       "      <td>[1890, 720, 21, 921, 1680, 13786, 257, 19443, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66542</th>\n",
       "      <td>Brad Paisley Debuts A Little Ditty About North...</td>\n",
       "      <td>[30805, 11243, 271, 1636, 1024, 4360, 82, 317,...</td>\n",
       "      <td>[30805, 11243, 271, 1636, 1024, 4360, 82, 317,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91949</th>\n",
       "      <td>Video Shows Man Holding Gun Before Allegedly S...</td>\n",
       "      <td>[10798, 25156, 1869, 31703, 6748, 7413, 26326,...</td>\n",
       "      <td>[10798, 25156, 1869, 31703, 6748, 7413, 26326,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117668</th>\n",
       "      <td>San Francisco Radio Stations Ban Lorde's 'Roya...</td>\n",
       "      <td>[15017, 6033, 8829, 520, 602, 10274, 4453, 68,...</td>\n",
       "      <td>[15017, 6033, 8829, 520, 602, 10274, 4453, 68,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "121815  Celebrities Emerging From Water Because Hey .....   \n",
       "76633   Bill Maher Slams The Internet For Killing The ...   \n",
       "188697  The Most Expensive NFL Tickets Of The Season: ...   \n",
       "80361   Students Surprise Starbucks Employee With Gene...   \n",
       "65636   Ben Stein: 'I Don't Think Trump Knows A Goddam...   \n",
       "...                                                   ...   \n",
       "43356   Trump's \"Extreme Vetting\" Of Refugees Empowers...   \n",
       "113206  For $6 You Can Give a Coffee Tree and Help Emp...   \n",
       "66542   Brad Paisley Debuts A Little Ditty About North...   \n",
       "91949   Video Shows Man Holding Gun Before Allegedly S...   \n",
       "117668  San Francisco Radio Stations Ban Lorde's 'Roya...   \n",
       "\n",
       "                                                tokenized  \\\n",
       "121815  [42741, 65, 19491, 48297, 3574, 5638, 4362, 14...   \n",
       "76633   [17798, 38137, 30382, 82, 383, 4455, 1114, 255...   \n",
       "188697  [464, 4042, 5518, 2021, 5134, 26878, 3226, 383...   \n",
       "80361   [28239, 47893, 24527, 36824, 2080, 2980, 516, ...   \n",
       "65636   [11696, 15215, 25, 705, 40, 2094, 470, 11382, ...   \n",
       "...                                                   ...   \n",
       "43356   [6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...   \n",
       "113206  [1890, 720, 21, 921, 1680, 13786, 257, 19443, ...   \n",
       "66542   [30805, 11243, 271, 1636, 1024, 4360, 82, 317,...   \n",
       "91949   [10798, 25156, 1869, 31703, 6748, 7413, 26326,...   \n",
       "117668  [15017, 6033, 8829, 520, 602, 10274, 4453, 68,...   \n",
       "\n",
       "                                                   padded  \n",
       "121815  [42741, 65, 19491, 48297, 3574, 5638, 4362, 14...  \n",
       "76633   [17798, 38137, 30382, 82, 383, 4455, 1114, 255...  \n",
       "188697  [464, 4042, 5518, 2021, 5134, 26878, 3226, 383...  \n",
       "80361   [28239, 47893, 24527, 36824, 2080, 2980, 516, ...  \n",
       "65636   [11696, 15215, 25, 705, 40, 2094, 470, 11382, ...  \n",
       "...                                                   ...  \n",
       "43356   [6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...  \n",
       "113206  [1890, 720, 21, 921, 1680, 13786, 257, 19443, ...  \n",
       "66542   [30805, 11243, 271, 1636, 1024, 4360, 82, 317,...  \n",
       "91949   [10798, 25156, 1869, 31703, 6748, 7413, 26326,...  \n",
       "117668  [15017, 6033, 8829, 520, 602, 10274, 4453, 68,...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df.sample(n=100, random_state=42)  # Random 100 rows\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf4716-2732-4b57-9075-d08035a8d6bb",
   "metadata": {},
   "source": [
    "##### Define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b78f17-bab1-4bd9-82d5-e46243275944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    def __init__(self, df_subset):\n",
    "        self.input_ids = torch.tensor(df_subset[\"padded\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = (self.input_ids != tokenizer.pad_token_id).long()  # Mask padding tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.input_ids[idx],  # GPT-2 is trained using its own inputs as labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c714cf26-ae62-4571-a786-8db3dfd6d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "train_size = int(0.8 * len(df_subset))\n",
    "train_df, val_df = df_subset[:train_size], df_subset[train_size:]\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = GPT2Dataset(train_df)\n",
    "val_dataset = GPT2Dataset(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e27f5-a30a-4a85-b7ea-b32347d64e91",
   "metadata": {},
   "source": [
    "DistilGPT2 has 6 transformer blocks compared to GPT2, which has 12 transformer blocks. To perform transfer learning properly we will freeze all layers and unfreeze the last 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6b72c0-57f4-4d2f-8204-c9d1e9e185d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pretrained GPT-2 Model with LM head\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")  # 50% smaller\n",
    "\n",
    "# Freeze all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last 4 layers\n",
    "for param in model.transformer.h[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move Model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fbe5c-0753-497e-870e-defa8b9f724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0cbdb-3e15-4d7a-8808-a3c1ae096168",
   "metadata": {},
   "source": [
    "##### Choose a batch size and num workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fc1028-e5e2-4fe1-a946-62d06d8334f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and data loaders ready!\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, num_workers=1, shuffle=True)  # Reduce num_workers\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, num_workers=1, shuffle=False)\n",
    "\n",
    "print(\"Model and data loaders ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a45e60-1d43-46bd-a44f-14c1bdc885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set Hugging Face Transformers library to show debug logs\n",
    "transformers.logging.set_verbosity_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c348a2-6418-42e2-ac24-be7d2c6acbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Using device: cuda\n",
      "🚀 GPU Name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "💾 GPU Memory Allocated: 319.24 MB\n",
      "💾 GPU Memory Reserved: 356.00 MB\n",
      "🔄 CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "# Print selected device\n",
    "print(f\"🔥 Using device: {device}\")\n",
    "\n",
    "# Print GPU info\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"🚀 GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"💾 GPU Memory Reserved: {torch.cuda.memory_reserved(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"🔄 CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"🖥 Running on CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f3048-0348-4804-b2c4-17d67134e677",
   "metadata": {},
   "source": [
    "Reducing Learning Rate\n",
    "Why? A high learning rate can cause large weight updates, leading to overwriting GPT-2’s pre-trained knowledge.\n",
    "How? Use a smaller learning rate than usual when fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e014f55-8bfc-4e86-8210-e87002b47232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Where model checkpoints will be saved\n",
    "    logging_dir=\"./logs\",  # Directory for logging\n",
    "    logging_strategy=\"steps\",  # Log at every step\n",
    "    logging_steps=50,  # Log every 50 steps\n",
    "    report_to=[\"tensorboard\"],  # Log to TensorBoard\n",
    "    eval_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",  # Save model at each epoch\n",
    "    save_total_limit=5,  # Keep only last 2 checkpoints\n",
    "    disable_tqdm=False,  # Enable progress bars\n",
    "    load_best_model_at_end=True,  # Load best model checkpoint at end\n",
    "    fp16=True,  # Enable mixed precision for speed\n",
    "    per_device_train_batch_size=8,  # Adjust batch size to prevent memory issues\n",
    "    per_device_eval_batch_size=8,  # Same for evaluation\n",
    "    gradient_accumulation_steps=1,  # Accumulate gradients before updating weights\n",
    "    learning_rate=5e-5, # Lower than usual (default is 5e-4)\n",
    "    weight_decay=0.01,  # Prevent drastic weight changes\n",
    "    num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73bbf9f5-e19e-4431-bcd8-93452750393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer.Trainer object at 0x7f8b193c41c0>\n"
     ]
    }
   ],
   "source": [
    "# Use Hugging Face Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e9e0b15-d114-40cd-929b-20fa08079cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n",
      "  Number of trainable parameters = 14,175,744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.462164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.242053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.740644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Configuration saved in ./results/checkpoint-10/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-10/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Configuration saved in ./results/checkpoint-20/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-20/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Configuration saved in ./results/checkpoint-30/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-30/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-30 (score: 0.7406437397003174).\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "# Measure start time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"🚀 Training started...\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432f471a-d540-4643-923e-50b18cbc1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed in 23.14 seconds (0.39 minutes)\n",
      "📈 Final Epoch: 3.0\n",
      "📊 Total Training Steps: 30\n"
     ]
    }
   ],
   "source": [
    "training_duration = end_time - start_time\n",
    "# Print training duration\n",
    "print(f\"✅ Training completed in {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "\n",
    "# Print final training state\n",
    "print(f\"📈 Final Epoch: {trainer.state.epoch}\")\n",
    "print(f\"📊 Total Training Steps: {trainer.state.global_step}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f8a5a-2515-46c5-868d-b3722c8c099e",
   "metadata": {},
   "source": [
    "##### Run this command in the terminal for training metrics in tensorboard\n",
    "\n",
    "`tensorboard --logdir=./logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46ca0ac8-8dc8-4724-8ced-0e35501cc4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../models/gpt2-v1/gpt2_finetuned/config.json\n",
      "Configuration saved in ../models/gpt2-v1/gpt2_finetuned/generation_config.json\n",
      "Model weights saved in ../models/gpt2-v1/gpt2_finetuned/model.safetensors\n",
      "tokenizer config file saved in ../models/gpt2-v1/gpt2_finetuned/tokenizer_config.json\n",
      "Special tokens file saved in ../models/gpt2-v1/gpt2_finetuned/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"../models/gpt2-v1/gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"../models/gpt2-v1/gpt2_finetuned\")\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "796120ec-db98-4cca-9fd8-c004c6eeed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Evaluation Loss: 0.7406\n",
      "🔢 Perplexity: 2.0973\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "\n",
    "# Define function to calculate perplexity\n",
    "def compute_perplexity(eval_loss):\n",
    "    return np.exp(eval_loss)  # Perplexity = exp(loss)\n",
    "\n",
    "# Get evaluation loss from trainer\n",
    "eval_results = trainer.evaluate()\n",
    "eval_loss = eval_results[\"eval_loss\"]\n",
    "perplexity = compute_perplexity(eval_loss)\n",
    "\n",
    "print(f\"📝 Evaluation Loss: {eval_loss:.4f}\")\n",
    "print(f\"🔢 Perplexity: {perplexity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4fe578-c321-49c4-aece-46595f5463c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StopOnWhitespace(StoppingCriteria):\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Stop generation if the last 5 tokens are whitespace\n",
    "        if all(tokenizer.decode(tok).isspace() for tok in input_ids[0, -5:]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnWhitespace()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4acff34e-359c-4243-85b2-d37316530fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Input: Breaking news:\n",
      "🔮 Output: Breaking news: An American pastor who killed three teenage girls in Georgia has urged parents to pray as the church says its message never comes back because 'you want a happy world' MORE (W.Va.), along with other groups seeking prayer that won‡t be seen in the nation for too long, have pulled his story off at an Arlington Christian Community Church last weekend and is urging everyone not to become ‪irrespective of their faith\n",
      "\n",
      "📝 Input: Latest update:\n",
      "🔮 Output: Latest update: I added the last message from a previous version by telling you that they have been sent to Google for testing, but only since January 6th in March 2013 - this time.\n",
      "\n",
      "📝 Input: The president announced that\n",
      "🔮 Output: The president announced that the campaign was launching a new campaign in support of Hillary Clinton in July — something it has been doing all month and even now\n",
      "\n",
      "📝 Input: Scientists have discovered a new\n",
      "🔮 Output: Scientists have discovered a new, nearly identical particle to that found last spring. It may not even match what it's been before, especially if so few other particles were expected in 2016 or 2025\n",
      "\n",
      "📝 Input: Experts warn that\n",
      "🔮 Output: Experts warn that in some of America they may soon disappear, but even \"people who say the American Dream come true and prosper with it are still leaving our state,\" she told CNN. That includes President Trump on Friday and Sen. Jeff Sessions on Friday, former Alabama senator James Comey is now running a new bid to secure the job .\n",
      "\n",
      "📝 Input: A recent study suggests that\n",
      "🔮 Output: A recent study suggests that we should never be concerned about a person like me when they grow up,\" says Burdie Stolberth's, who is an occupational neurosurgeon at the University Hospital of Wisconsin. And he recently did it to convince doctors how to recognize brain disorders in his young age .\n",
      "\n",
      "📝 Input: Authorities have confirmed that\n",
      "🔮 Output: Authorities have confirmed that there has been no confirmation that the terrorist leader was known, after he was abducted from Turkey about a month ago on a Greek-Turkish trip. That person had not been allowed to visit Athens or Washington -- though it is also being alleged that this might help him in any new situation.\n",
      "\n",
      "\n",
      "\n",
      "While we believe that if these reports do actually appear, I‰#‎do_h\n",
      "\n",
      "📝 Input: In a surprising turn of events,\n",
      "🔮 Output: In a surprising turn of events, the city›s financial institutions closed Tuesday amid mounting claims it would close in 2016 by closing for several weeks after announcing its new plans last year\n",
      "\n",
      "📝 Input: The stock market responded to\n",
      "🔮 Output: The stock market responded to a spate of complaints in early September that they were taking actions to block the $25-a\n",
      "\n",
      "📝 Input: New regulations require companies to\n",
      "🔮 Output: New regulations require companies to submit their proposals online, or a new form that takes them to task — and they will now only have two options when required. Even if someone gets caught up in an app-specific scandal, many people lose their trust over what it can bring to their personal data (like any privacy protection scheme); they don't know what happens until the company is sued—which explains why everyone should start looking through the system first.\n",
      "\n",
      "📝 Input: Health officials recommend that\n",
      "🔮 Output: Health officials recommend that public schools reevaluation the education environment, not to make children worse off from kindergarten through school because so many children live more safely in America than a large-scale industry with an economy of $11.1 billion on hand is being forced into disjointed state curricula (\n",
      "\n",
      "📝 Input: Technology companies are investing in\n",
      "🔮 Output: Technology companies are investing in innovation that can be improved when the supply curve is as large or larger and, hopefully with a boost from existing investments.\n",
      "\n",
      "📝 Input: Sports fans are excited about\n",
      "🔮 Output: Sports fans are excited about how they're getting in-season football, including what we'll call a ‪Season 12 playoff’ with the New York Rangers on March 31\n",
      "\n",
      "📝 Input: The weather forecast predicts\n",
      "🔮 Output: The weather forecast predicts the average price tag will be just over 50% at next election year (AFP Photo/Sachary J. Buhlenman)\n",
      "A new British thermal analysis from the energy research group Stratfor warns that the worst wind storm for the global warming has yet been recorded this season or so, and an \"unprecedented chance\" of its being expected on Thursday\n",
      "\n",
      "📝 Input: Researchers at MIT have developed\n",
      "🔮 Output: Researchers at MIT have developed a computer-computer algorithm and its system for the creation of advanced software platforms, which are particularly well suited to producing scientific applications\n",
      "\n",
      "📝 Input: Protests erupted in the city over\n",
      "🔮 Output: Protests erupted in the city over security measures at the protest on Saturday when some young men who had reportedly threatened to take out police vehicles began yelling ‰يرة رعبوظاه\n",
      "\n",
      "📝 Input: The Supreme Court ruled that\n",
      "🔮 Output: The Supreme Court ruled that California can't legally deny driver insurance on those who work or hire others for private driving, even though applicants often claim they must be licensed through a state license number and have the option of obtaining licenses from the local commission. \"California may also mandate to pay for transportation services if there are not qualified drivers using any means which might affect their job satisfaction or personal finances,\" Davis said at trial following a ruling June 26.\n",
      "\n",
      "📝 Input: Celebrities are reacting to\n",
      "🔮 Output: Celebrities are reacting to the situation by telling people what‰ they really want and how hard it is for them, particularly their daughters and even some young men\n",
      "\n",
      "📝 Input: A new breakthrough in medicine shows that\n",
      "🔮 Output: A new breakthrough in medicine shows that patients with cancer have to take precautions to prevent transmission and death by developing novel anti-anilotropic drugs (IPS). It's believed as a promising new avenue for treatment, especially on the side — that we could become safer around cancers.‹\n",
      "\n",
      "📝 Input: The United Nations has issued a statement on\n",
      "🔮 Output: The United Nations has issued a statement on Syria, demanding that Turkey take responsibility for air strikes \"before the conflict is over (with no more) or in less likely to continue with the regime,\" The Middle East Online reported today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, top_p=0.9, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=100,\n",
    "        min_length=20,\n",
    "        do_sample=True,\n",
    "        num_beams=10,\n",
    "        length_penalty=1,\n",
    "        early_stopping=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Ensure it doesn't stop early due to padding\n",
    "        temperature=10.1,  # Increase randomness\n",
    "        top_p=top_p,  # Nucleus sampling (limits probability mass)\n",
    "        top_k=top_k,  # Only consider the top-k most likely words\n",
    "        repetition_penalty=2.1,  # Avoid repeated spaces\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True).strip()  # Strip extra spaces\n",
    "\n",
    "# Test with new settings\n",
    "examples = [\n",
    "    \"Breaking news:\", \n",
    "    \"Latest update:\", \n",
    "    \"The president announced that\",\n",
    "    \"Scientists have discovered a new\",\n",
    "    \"Experts warn that\",\n",
    "    \"A recent study suggests that\",\n",
    "    \"Authorities have confirmed that\",\n",
    "    \"In a surprising turn of events,\",\n",
    "    \"The stock market responded to\",\n",
    "    \"New regulations require companies to\",\n",
    "    \"Health officials recommend that\",\n",
    "    \"Technology companies are investing in\",\n",
    "    \"Sports fans are excited about\",\n",
    "    \"The weather forecast predicts\",\n",
    "    \"Researchers at MIT have developed\",\n",
    "    \"Protests erupted in the city over\",\n",
    "    \"The Supreme Court ruled that\",\n",
    "    \"Celebrities are reacting to\",\n",
    "    \"A new breakthrough in medicine shows that\",\n",
    "    \"The United Nations has issued a statement on\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    print(f\"📝 Input: {text}\")\n",
    "    print(f\"🔮 Output: {generate_text(text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc8214ce-464f-4fc1-990c-61047fc6ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Encoded Input: tensor([[29449,  1705,    25]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Breaking news:\", return_tensors=\"pt\").to(device)\n",
    "print(\"🔎 Encoded Input:\", input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba46cca-d050-4be2-a0c2-8f21754e3318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Starting prompt: The United Nations has issued a statement on\n",
      "\n",
      "🔍 Token step 1\n",
      "   the: 0.2629\n",
      "   Tuesday: 0.0802\n",
      "   its: 0.0777\n",
      "   Monday: 0.0730\n",
      "   Wednesday: 0.0707\n",
      "\n",
      "🔍 Token step 2\n",
      "   situation: 0.1036\n",
      "   issue: 0.0358\n",
      "   matter: 0.0326\n",
      "   crisis: 0.0231\n",
      "   incident: 0.0204\n",
      "\n",
      "🔍 Token step 3\n",
      "   in: 0.4491\n",
      "  .: 0.1002\n",
      "  ,: 0.0884\n",
      "   and: 0.0627\n",
      "   with: 0.0405\n",
      "\n",
      "🔍 Token step 4\n",
      "   Syria: 0.3931\n",
      "   Yemen: 0.0905\n",
      "   Ukraine: 0.0516\n",
      "   the: 0.0427\n",
      "   Gaza: 0.0414\n",
      "\n",
      "🔍 Token step 5\n",
      "  ,: 0.3221\n",
      "  .: 0.2079\n",
      "   and: 0.0923\n",
      "  :: 0.0494\n",
      "   that: 0.0385\n",
      "\n",
      "🔍 Token step 6\n",
      "   saying: 0.2135\n",
      "   calling: 0.1378\n",
      "   which: 0.0575\n",
      "   and: 0.0476\n",
      "   warning: 0.0371\n",
      "\n",
      "🔍 Token step 7\n",
      "   that: 0.2609\n",
      "   it: 0.1908\n",
      "   the: 0.1684\n",
      "  :: 0.0960\n",
      "   there: 0.0321\n",
      "\n",
      "🔍 Token step 8\n",
      "   the: 0.2347\n",
      "   it: 0.0978\n",
      "   \": 0.0672\n",
      "   there: 0.0434\n",
      "   a: 0.0280\n",
      "\n",
      "🔍 Token step 9\n",
      "   Syrian: 0.1529\n",
      "   situation: 0.0793\n",
      "   government: 0.0545\n",
      "   country: 0.0438\n",
      "   United: 0.0412\n",
      "\n",
      "🔍 Token step 10\n",
      "   government: 0.6223\n",
      "   army: 0.0511\n",
      "   regime: 0.0465\n",
      "   people: 0.0362\n",
      "   civil: 0.0310\n",
      "\n",
      "🔍 Token step 11\n",
      "   has: 0.3182\n",
      "   is: 0.1991\n",
      "   had: 0.0607\n",
      "   and: 0.0431\n",
      "  's: 0.0405\n",
      "\n",
      "🔍 Token step 12\n",
      "   been: 0.1192\n",
      "   not: 0.0723\n",
      "   \": 0.0679\n",
      "   no: 0.0274\n",
      "   taken: 0.0250\n",
      "\n",
      "🔍 Token step 13\n",
      "   \": 0.1035\n",
      "   unable: 0.0711\n",
      "   responsible: 0.0431\n",
      "   using: 0.0358\n",
      "   �: 0.0297\n",
      "\n",
      "🔍 Token step 14\n",
      "  in: 0.0287\n",
      "  dis: 0.0278\n",
      "  completely: 0.0223\n",
      "  ab: 0.0191\n",
      "  t: 0.0174\n",
      "\n",
      "🔍 Token step 15\n",
      "   the: 0.1285\n",
      "   a: 0.0830\n",
      "   constant: 0.0473\n",
      "   direct: 0.0430\n",
      "   contact: 0.0404\n",
      "\n",
      "🔍 Token step 16\n",
      "   process: 0.2369\n",
      "   wrong: 0.1019\n",
      "   midst: 0.0722\n",
      "   thro: 0.0438\n",
      "   dark: 0.0331\n",
      "\n",
      "🔍 Token step 17\n",
      "   of: 0.9542\n",
      "  \": 0.0327\n",
      "   and: 0.0042\n",
      "   for: 0.0010\n",
      "  ,: 0.0010\n",
      "\n",
      "🔍 Token step 18\n",
      "   taking: 0.0320\n",
      "   destroying: 0.0320\n",
      "   stabil: 0.0206\n",
      "   trying: 0.0151\n",
      "   fighting: 0.0151\n",
      "\n",
      "🔍 Token step 19\n",
      "   over: 0.2372\n",
      "   control: 0.1847\n",
      "   the: 0.0513\n",
      "   steps: 0.0467\n",
      "   a: 0.0342\n",
      "\n",
      "🔍 Token step 20\n",
      "   the: 0.2894\n",
      "   control: 0.0503\n",
      "   large: 0.0444\n",
      "   a: 0.0404\n",
      "  \": 0.0380\n",
      "\n",
      "📝 Final generated text:\n",
      "The United Nations has issued a statement on the situation in Syria, saying that the Syrian government has been \"in the process of taking over the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_with_token_probabilities(prompt, max_tokens=20):\n",
    "    \"\"\"Generate text token by token, displaying each step with probabilities.\"\"\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    print(f\"📝 Starting prompt: {prompt}\")\n",
    "    generated_text = prompt\n",
    "\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs.logits  # Raw model outputs\n",
    "        \n",
    "        # Get probability distribution for next token\n",
    "        probs = torch.softmax(logits[0, -1, :], dim=-1)  \n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "\n",
    "        # Print top token choices\n",
    "        print(f\"\\n🔍 Token step {_+1}\")\n",
    "        for i in range(5):  # Show top 5 predictions\n",
    "            token = tokenizer.decode([sorted_indices[i].item()])\n",
    "            print(f\"  {token}: {sorted_probs[i].item():.4f}\")\n",
    "\n",
    "        # Select most probable token\n",
    "        next_token_id = sorted_indices[0].item()\n",
    "        next_token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        # Append token to generated text\n",
    "        generated_text += next_token\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "\n",
    "        # Stop if end token is reached\n",
    "        if next_token == tokenizer.eos_token:\n",
    "            print(\"\\n🚫 End of text token reached.\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n📝 Final generated text:\")\n",
    "    print(generated_text)\n",
    "\n",
    "# Test the function\n",
    "generate_with_token_probabilities(\"The United Nations has issued a statement on\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef089eb8-2c9d-4933-8c83-68d81b52298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679dfdc-7afe-42ef-a236-aa2d6c893a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
