{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8385cdb2-d8a2-4bbe-9a41-99af85930c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adma224/anaconda3/envs/ml-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import transformers\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8920a22-47c9-4f9a-ab94-2c3df9bfbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Set device ONCE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ‚úÖ Memory optimizations (move these up)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.set_per_process_memory_fraction(0.6, device=0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Limit GPU & CPU usage\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Limit CPU threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb21099-2769-4592-9941-656f28ab8626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/cleaned_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb4ed7e-3ed0-4db2-8806-79d3c5a9da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207996 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline\n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1       American Airlines Flyer Charged, Banned For Li...\n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "3       The Funniest Tweets From Parents This Week (Se...\n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...\n",
       "...                                                   ...\n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...\n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...\n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...\n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...\n",
       "\n",
       "[207996 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3c30db-a4f2-4b68-9533-3bad9d61f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"headline\"]).copy()  # Remove rows where 'headline' is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa1208c-2487-4ed9-833a-7d91cdb8244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have padding by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c887ae-60ab-4a55-aec6-2660bc04d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"tokenized\"] = df[\"headline\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "max_length = max(len(tokens) for tokens in df[\"tokenized\"])\n",
    "\n",
    "df.loc[:, \"padded\"] = df[\"tokenized\"].apply(lambda x: x + [tokenizer.pad_token_id] * (max_length - len(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0065bb00-bb7d-44ad-90bf-2566aa67ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121815</th>\n",
       "      <td>Celebrities Emerging From Water Because Hey .....</td>\n",
       "      <td>[42741, 65, 19491, 48297, 3574, 5638, 4362, 14...</td>\n",
       "      <td>[42741, 65, 19491, 48297, 3574, 5638, 4362, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76633</th>\n",
       "      <td>Bill Maher Slams The Internet For Killing The ...</td>\n",
       "      <td>[17798, 38137, 30382, 82, 383, 4455, 1114, 255...</td>\n",
       "      <td>[17798, 38137, 30382, 82, 383, 4455, 1114, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188697</th>\n",
       "      <td>The Most Expensive NFL Tickets Of The Season: ...</td>\n",
       "      <td>[464, 4042, 5518, 2021, 5134, 26878, 3226, 383...</td>\n",
       "      <td>[464, 4042, 5518, 2021, 5134, 26878, 3226, 383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80361</th>\n",
       "      <td>Students Surprise Starbucks Employee With Gene...</td>\n",
       "      <td>[28239, 47893, 24527, 36824, 2080, 2980, 516, ...</td>\n",
       "      <td>[28239, 47893, 24527, 36824, 2080, 2980, 516, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65636</th>\n",
       "      <td>Ben Stein: 'I Don't Think Trump Knows A Goddam...</td>\n",
       "      <td>[11696, 15215, 25, 705, 40, 2094, 470, 11382, ...</td>\n",
       "      <td>[11696, 15215, 25, 705, 40, 2094, 470, 11382, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43356</th>\n",
       "      <td>Trump's \"Extreme Vetting\" Of Refugees Empowers...</td>\n",
       "      <td>[6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...</td>\n",
       "      <td>[6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113206</th>\n",
       "      <td>For $6 You Can Give a Coffee Tree and Help Emp...</td>\n",
       "      <td>[1890, 720, 21, 921, 1680, 13786, 257, 19443, ...</td>\n",
       "      <td>[1890, 720, 21, 921, 1680, 13786, 257, 19443, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66542</th>\n",
       "      <td>Brad Paisley Debuts A Little Ditty About North...</td>\n",
       "      <td>[30805, 11243, 271, 1636, 1024, 4360, 82, 317,...</td>\n",
       "      <td>[30805, 11243, 271, 1636, 1024, 4360, 82, 317,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91949</th>\n",
       "      <td>Video Shows Man Holding Gun Before Allegedly S...</td>\n",
       "      <td>[10798, 25156, 1869, 31703, 6748, 7413, 26326,...</td>\n",
       "      <td>[10798, 25156, 1869, 31703, 6748, 7413, 26326,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117668</th>\n",
       "      <td>San Francisco Radio Stations Ban Lorde's 'Roya...</td>\n",
       "      <td>[15017, 6033, 8829, 520, 602, 10274, 4453, 68,...</td>\n",
       "      <td>[15017, 6033, 8829, 520, 602, 10274, 4453, 68,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "121815  Celebrities Emerging From Water Because Hey .....   \n",
       "76633   Bill Maher Slams The Internet For Killing The ...   \n",
       "188697  The Most Expensive NFL Tickets Of The Season: ...   \n",
       "80361   Students Surprise Starbucks Employee With Gene...   \n",
       "65636   Ben Stein: 'I Don't Think Trump Knows A Goddam...   \n",
       "...                                                   ...   \n",
       "43356   Trump's \"Extreme Vetting\" Of Refugees Empowers...   \n",
       "113206  For $6 You Can Give a Coffee Tree and Help Emp...   \n",
       "66542   Brad Paisley Debuts A Little Ditty About North...   \n",
       "91949   Video Shows Man Holding Gun Before Allegedly S...   \n",
       "117668  San Francisco Radio Stations Ban Lorde's 'Roya...   \n",
       "\n",
       "                                                tokenized  \\\n",
       "121815  [42741, 65, 19491, 48297, 3574, 5638, 4362, 14...   \n",
       "76633   [17798, 38137, 30382, 82, 383, 4455, 1114, 255...   \n",
       "188697  [464, 4042, 5518, 2021, 5134, 26878, 3226, 383...   \n",
       "80361   [28239, 47893, 24527, 36824, 2080, 2980, 516, ...   \n",
       "65636   [11696, 15215, 25, 705, 40, 2094, 470, 11382, ...   \n",
       "...                                                   ...   \n",
       "43356   [6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...   \n",
       "113206  [1890, 720, 21, 921, 1680, 13786, 257, 19443, ...   \n",
       "66542   [30805, 11243, 271, 1636, 1024, 4360, 82, 317,...   \n",
       "91949   [10798, 25156, 1869, 31703, 6748, 7413, 26326,...   \n",
       "117668  [15017, 6033, 8829, 520, 602, 10274, 4453, 68,...   \n",
       "\n",
       "                                                   padded  \n",
       "121815  [42741, 65, 19491, 48297, 3574, 5638, 4362, 14...  \n",
       "76633   [17798, 38137, 30382, 82, 383, 4455, 1114, 255...  \n",
       "188697  [464, 4042, 5518, 2021, 5134, 26878, 3226, 383...  \n",
       "80361   [28239, 47893, 24527, 36824, 2080, 2980, 516, ...  \n",
       "65636   [11696, 15215, 25, 705, 40, 2094, 470, 11382, ...  \n",
       "...                                                   ...  \n",
       "43356   [6170, 338, 366, 36716, 569, 35463, 1, 3226, 3...  \n",
       "113206  [1890, 720, 21, 921, 1680, 13786, 257, 19443, ...  \n",
       "66542   [30805, 11243, 271, 1636, 1024, 4360, 82, 317,...  \n",
       "91949   [10798, 25156, 1869, 31703, 6748, 7413, 26326,...  \n",
       "117668  [15017, 6033, 8829, 520, 602, 10274, 4453, 68,...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df.sample(n=100, random_state=42)  # Random 100 rows\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf4716-2732-4b57-9075-d08035a8d6bb",
   "metadata": {},
   "source": [
    "##### Define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b78f17-bab1-4bd9-82d5-e46243275944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    def __init__(self, df_subset):\n",
    "        self.input_ids = torch.tensor(df_subset[\"padded\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = (self.input_ids != tokenizer.pad_token_id).long()  # Mask padding tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.input_ids[idx],  # GPT-2 is trained using its own inputs as labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c714cf26-ae62-4571-a786-8db3dfd6d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "train_size = int(0.8 * len(df_subset))\n",
    "train_df, val_df = df_subset[:train_size], df_subset[train_size:]\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = GPT2Dataset(train_df)\n",
    "val_dataset = GPT2Dataset(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e27f5-a30a-4a85-b7ea-b32347d64e91",
   "metadata": {},
   "source": [
    "DistilGPT2 has 6 transformer blocks compared to GPT2, which has 12 transformer blocks. To perform transfer learning properly we will freeze all layers and unfreeze the last 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6b72c0-57f4-4d2f-8204-c9d1e9e185d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pretrained GPT-2 Model with LM head\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")  # 50% smaller\n",
    "\n",
    "# Freeze all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last 4 layers\n",
    "for param in model.transformer.h[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move Model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fbe5c-0753-497e-870e-defa8b9f724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0cbdb-3e15-4d7a-8808-a3c1ae096168",
   "metadata": {},
   "source": [
    "##### Choose a batch size and num workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fc1028-e5e2-4fe1-a946-62d06d8334f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and data loaders ready!\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, num_workers=1, shuffle=True)  # Reduce num_workers\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, num_workers=1, shuffle=False)\n",
    "\n",
    "print(\"Model and data loaders ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a45e60-1d43-46bd-a44f-14c1bdc885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set Hugging Face Transformers library to show debug logs\n",
    "transformers.logging.set_verbosity_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c348a2-6418-42e2-ac24-be7d2c6acbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: cuda\n",
      "üöÄ GPU Name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "üíæ GPU Memory Allocated: 319.24 MB\n",
      "üíæ GPU Memory Reserved: 356.00 MB\n",
      "üîÑ CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "# Print selected device\n",
    "print(f\"üî• Using device: {device}\")\n",
    "\n",
    "# Print GPU info\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"üöÄ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"üíæ GPU Memory Reserved: {torch.cuda.memory_reserved(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"üîÑ CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"üñ• Running on CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f3048-0348-4804-b2c4-17d67134e677",
   "metadata": {},
   "source": [
    "Reducing Learning Rate\n",
    "Why? A high learning rate can cause large weight updates, leading to overwriting GPT-2‚Äôs pre-trained knowledge.\n",
    "How? Use a smaller learning rate than usual when fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e014f55-8bfc-4e86-8210-e87002b47232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Where model checkpoints will be saved\n",
    "    logging_dir=\"./logs\",  # Directory for logging\n",
    "    logging_strategy=\"steps\",  # Log at every step\n",
    "    logging_steps=50,  # Log every 50 steps\n",
    "    report_to=[\"tensorboard\"],  # Log to TensorBoard\n",
    "    eval_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",  # Save model at each epoch\n",
    "    save_total_limit=5,  # Keep only last 2 checkpoints\n",
    "    disable_tqdm=False,  # Enable progress bars\n",
    "    load_best_model_at_end=True,  # Load best model checkpoint at end\n",
    "    fp16=True,  # Enable mixed precision for speed\n",
    "    per_device_train_batch_size=8,  # Adjust batch size to prevent memory issues\n",
    "    per_device_eval_batch_size=8,  # Same for evaluation\n",
    "    gradient_accumulation_steps=1,  # Accumulate gradients before updating weights\n",
    "    learning_rate=5e-5, # Lower than usual (default is 5e-4)\n",
    "    weight_decay=0.01,  # Prevent drastic weight changes\n",
    "    num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73bbf9f5-e19e-4431-bcd8-93452750393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer.Trainer object at 0x7f8b193c41c0>\n"
     ]
    }
   ],
   "source": [
    "# Use Hugging Face Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e9e0b15-d114-40cd-929b-20fa08079cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n",
      "  Number of trainable parameters = 14,175,744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.462164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.242053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.740644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Configuration saved in ./results/checkpoint-10/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-10/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Configuration saved in ./results/checkpoint-20/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-20/model.safetensors\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Configuration saved in ./results/checkpoint-30/generation_config.json\n",
      "Model weights saved in ./results/checkpoint-30/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-30 (score: 0.7406437397003174).\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "# Measure start time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"üöÄ Training started...\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432f471a-d540-4643-923e-50b18cbc1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed in 23.14 seconds (0.39 minutes)\n",
      "üìà Final Epoch: 3.0\n",
      "üìä Total Training Steps: 30\n"
     ]
    }
   ],
   "source": [
    "training_duration = end_time - start_time\n",
    "# Print training duration\n",
    "print(f\"‚úÖ Training completed in {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "\n",
    "# Print final training state\n",
    "print(f\"üìà Final Epoch: {trainer.state.epoch}\")\n",
    "print(f\"üìä Total Training Steps: {trainer.state.global_step}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f8a5a-2515-46c5-868d-b3722c8c099e",
   "metadata": {},
   "source": [
    "##### Run this command in the terminal for training metrics in tensorboard\n",
    "\n",
    "`tensorboard --logdir=./logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46ca0ac8-8dc8-4724-8ced-0e35501cc4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../models/gpt2-v1/gpt2_finetuned/config.json\n",
      "Configuration saved in ../models/gpt2-v1/gpt2_finetuned/generation_config.json\n",
      "Model weights saved in ../models/gpt2-v1/gpt2_finetuned/model.safetensors\n",
      "tokenizer config file saved in ../models/gpt2-v1/gpt2_finetuned/tokenizer_config.json\n",
      "Special tokens file saved in ../models/gpt2-v1/gpt2_finetuned/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"../models/gpt2-v1/gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"../models/gpt2-v1/gpt2_finetuned\")\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "796120ec-db98-4cca-9fd8-c004c6eeed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Evaluation Loss: 0.7406\n",
      "üî¢ Perplexity: 2.0973\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "\n",
    "# Define function to calculate perplexity\n",
    "def compute_perplexity(eval_loss):\n",
    "    return np.exp(eval_loss)  # Perplexity = exp(loss)\n",
    "\n",
    "# Get evaluation loss from trainer\n",
    "eval_results = trainer.evaluate()\n",
    "eval_loss = eval_results[\"eval_loss\"]\n",
    "perplexity = compute_perplexity(eval_loss)\n",
    "\n",
    "print(f\"üìù Evaluation Loss: {eval_loss:.4f}\")\n",
    "print(f\"üî¢ Perplexity: {perplexity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4fe578-c321-49c4-aece-46595f5463c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StopOnWhitespace(StoppingCriteria):\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Stop generation if the last 5 tokens are whitespace\n",
    "        if all(tokenizer.decode(tok).isspace() for tok in input_ids[0, -5:]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnWhitespace()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4acff34e-359c-4243-85b2-d37316530fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Input: Breaking news:\n",
      "üîÆ Output: Breaking news: An American pastor who killed three teenage girls in Georgia has urged parents to pray as the church says its message never comes back because 'you want a happy world' MORE (W.Va.), along with other groups seeking prayer that won‚Ä°t be seen in the nation for too long, have pulled his story off at an Arlington Christian Community Church last weekend and is urging everyone not to become ‚Ä™irrespective of their faith\n",
      "\n",
      "üìù Input: Latest update:\n",
      "üîÆ Output: Latest update: I added the last message from a previous version by telling you that they have been sent to Google for testing, but only since January 6th in March 2013 - this time.\n",
      "\n",
      "üìù Input: The president announced that\n",
      "üîÆ Output: The president announced that the campaign was launching a new campaign in support of Hillary Clinton in July ‚Äî something it has been doing all month and even now\n",
      "\n",
      "üìù Input: Scientists have discovered a new\n",
      "üîÆ Output: Scientists have discovered a new, nearly identical particle to that found last spring. It may not even match what it's been before, especially if so few other particles were expected in 2016 or 2025\n",
      "\n",
      "üìù Input: Experts warn that\n",
      "üîÆ Output: Experts warn that in some of America they may soon disappear, but even \"people who say the American Dream come true and prosper with it are still leaving our state,\" she told CNN. That includes President Trump on Friday and Sen. Jeff Sessions on Friday, former Alabama senator James Comey is now running a new bid to secure the job .\n",
      "\n",
      "üìù Input: A recent study suggests that\n",
      "üîÆ Output: A recent study suggests that we should never be concerned about a person like me when they grow up,\" says Burdie Stolberth's, who is an occupational neurosurgeon at the University Hospital of Wisconsin. And he recently did it to convince doctors how to recognize brain disorders in his young age .\n",
      "\n",
      "üìù Input: Authorities have confirmed that\n",
      "üîÆ Output: Authorities have confirmed that there has been no confirmation that the terrorist leader was known, after he was abducted from Turkey about a month ago on a Greek-Turkish trip. That person had not been allowed to visit Athens or Washington -- though it is also being alleged that this might help him in any new situation.\n",
      "\n",
      "\n",
      "\n",
      "While we believe that if these reports do actually appear, I‚Ä∞#‚Äédo_h\n",
      "\n",
      "üìù Input: In a surprising turn of events,\n",
      "üîÆ Output: In a surprising turn of events, the city‚Ä∫s financial institutions closed Tuesday amid mounting claims it would close in 2016 by closing for several weeks after announcing its new plans last year\n",
      "\n",
      "üìù Input: The stock market responded to\n",
      "üîÆ Output: The stock market responded to a spate of complaints in early September that they were taking actions to block the $25-a\n",
      "\n",
      "üìù Input: New regulations require companies to\n",
      "üîÆ Output: New regulations require companies to submit their proposals online, or a new form that takes them to task ‚Äî and they will now only have two options when required. Even if someone gets caught up in an app-specific scandal, many people lose their trust over what it can bring to their personal data (like any privacy protection scheme); they don't know what happens until the company is sued‚Äîwhich explains why everyone should start looking through the system first.\n",
      "\n",
      "üìù Input: Health officials recommend that\n",
      "üîÆ Output: Health officials recommend that public schools reevaluation the education environment, not to make children worse off from kindergarten through school because so many children live more safely in America than a large-scale industry with an economy of $11.1 billion on hand is being forced into disjointed state curricula (\n",
      "\n",
      "üìù Input: Technology companies are investing in\n",
      "üîÆ Output: Technology companies are investing in innovation that can be improved when the supply curve is as large or larger and, hopefully with a boost from existing investments.\n",
      "\n",
      "üìù Input: Sports fans are excited about\n",
      "üîÆ Output: Sports fans are excited about how they're getting in-season football, including what we'll call a ‚Ä™Season 12 playoff‚Äô with the New York Rangers on March 31\n",
      "\n",
      "üìù Input: The weather forecast predicts\n",
      "üîÆ Output: The weather forecast predicts the average price tag will be just over 50% at next election year (AFP Photo/Sachary J. Buhlenman)\n",
      "A new British thermal analysis from the energy research group Stratfor warns that the worst wind storm for the global warming has yet been recorded this season or so, and an \"unprecedented chance\" of its being expected on Thursday\n",
      "\n",
      "üìù Input: Researchers at MIT have developed\n",
      "üîÆ Output: Researchers at MIT have developed a computer-computer algorithm and its system for the creation of advanced software platforms, which are particularly well suited to producing scientific applications\n",
      "\n",
      "üìù Input: Protests erupted in the city over\n",
      "üîÆ Output: Protests erupted in the city over security measures at the protest on Saturday when some young men who had reportedly threatened to take out police vehicles began yelling ‚Ä∞Ÿäÿ±ÿ© ÿ±ÿπÿ®Ÿàÿ∏ÿßŸá\n",
      "\n",
      "üìù Input: The Supreme Court ruled that\n",
      "üîÆ Output: The Supreme Court ruled that California can't legally deny driver insurance on those who work or hire others for private driving, even though applicants often claim they must be licensed through a state license number and have the option of obtaining licenses from the local commission. \"California may also mandate to pay for transportation services if there are not qualified drivers using any means which might affect their job satisfaction or personal finances,\" Davis said at trial following a ruling June 26.\n",
      "\n",
      "üìù Input: Celebrities are reacting to\n",
      "üîÆ Output: Celebrities are reacting to the situation by telling people what‚Ä∞ they really want and how hard it is for them, particularly their daughters and even some young men\n",
      "\n",
      "üìù Input: A new breakthrough in medicine shows that\n",
      "üîÆ Output: A new breakthrough in medicine shows that patients with cancer have to take precautions to prevent transmission and death by developing novel anti-anilotropic drugs (IPS). It's believed as a promising new avenue for treatment, especially on the side ‚Äî that we could become safer around cancers.‚Äπ\n",
      "\n",
      "üìù Input: The United Nations has issued a statement on\n",
      "üîÆ Output: The United Nations has issued a statement on Syria, demanding that Turkey take responsibility for air strikes \"before the conflict is over (with no more) or in less likely to continue with the regime,\" The Middle East Online reported today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, top_p=0.9, top_k=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        max_length=100,\n",
    "        min_length=20,\n",
    "        do_sample=True,\n",
    "        num_beams=10,\n",
    "        length_penalty=1,\n",
    "        early_stopping=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Ensure it doesn't stop early due to padding\n",
    "        temperature=10.1,  # Increase randomness\n",
    "        top_p=top_p,  # Nucleus sampling (limits probability mass)\n",
    "        top_k=top_k,  # Only consider the top-k most likely words\n",
    "        repetition_penalty=2.1,  # Avoid repeated spaces\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True).strip()  # Strip extra spaces\n",
    "\n",
    "# Test with new settings\n",
    "examples = [\n",
    "    \"Breaking news:\", \n",
    "    \"Latest update:\", \n",
    "    \"The president announced that\",\n",
    "    \"Scientists have discovered a new\",\n",
    "    \"Experts warn that\",\n",
    "    \"A recent study suggests that\",\n",
    "    \"Authorities have confirmed that\",\n",
    "    \"In a surprising turn of events,\",\n",
    "    \"The stock market responded to\",\n",
    "    \"New regulations require companies to\",\n",
    "    \"Health officials recommend that\",\n",
    "    \"Technology companies are investing in\",\n",
    "    \"Sports fans are excited about\",\n",
    "    \"The weather forecast predicts\",\n",
    "    \"Researchers at MIT have developed\",\n",
    "    \"Protests erupted in the city over\",\n",
    "    \"The Supreme Court ruled that\",\n",
    "    \"Celebrities are reacting to\",\n",
    "    \"A new breakthrough in medicine shows that\",\n",
    "    \"The United Nations has issued a statement on\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    print(f\"üìù Input: {text}\")\n",
    "    print(f\"üîÆ Output: {generate_text(text)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc8214ce-464f-4fc1-990c-61047fc6ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Encoded Input: tensor([[29449,  1705,    25]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Breaking news:\", return_tensors=\"pt\").to(device)\n",
    "print(\"üîé Encoded Input:\", input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba46cca-d050-4be2-a0c2-8f21754e3318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Starting prompt: The United Nations has issued a statement on\n",
      "\n",
      "üîç Token step 1\n",
      "   the: 0.2629\n",
      "   Tuesday: 0.0802\n",
      "   its: 0.0777\n",
      "   Monday: 0.0730\n",
      "   Wednesday: 0.0707\n",
      "\n",
      "üîç Token step 2\n",
      "   situation: 0.1036\n",
      "   issue: 0.0358\n",
      "   matter: 0.0326\n",
      "   crisis: 0.0231\n",
      "   incident: 0.0204\n",
      "\n",
      "üîç Token step 3\n",
      "   in: 0.4491\n",
      "  .: 0.1002\n",
      "  ,: 0.0884\n",
      "   and: 0.0627\n",
      "   with: 0.0405\n",
      "\n",
      "üîç Token step 4\n",
      "   Syria: 0.3931\n",
      "   Yemen: 0.0905\n",
      "   Ukraine: 0.0516\n",
      "   the: 0.0427\n",
      "   Gaza: 0.0414\n",
      "\n",
      "üîç Token step 5\n",
      "  ,: 0.3221\n",
      "  .: 0.2079\n",
      "   and: 0.0923\n",
      "  :: 0.0494\n",
      "   that: 0.0385\n",
      "\n",
      "üîç Token step 6\n",
      "   saying: 0.2135\n",
      "   calling: 0.1378\n",
      "   which: 0.0575\n",
      "   and: 0.0476\n",
      "   warning: 0.0371\n",
      "\n",
      "üîç Token step 7\n",
      "   that: 0.2609\n",
      "   it: 0.1908\n",
      "   the: 0.1684\n",
      "  :: 0.0960\n",
      "   there: 0.0321\n",
      "\n",
      "üîç Token step 8\n",
      "   the: 0.2347\n",
      "   it: 0.0978\n",
      "   \": 0.0672\n",
      "   there: 0.0434\n",
      "   a: 0.0280\n",
      "\n",
      "üîç Token step 9\n",
      "   Syrian: 0.1529\n",
      "   situation: 0.0793\n",
      "   government: 0.0545\n",
      "   country: 0.0438\n",
      "   United: 0.0412\n",
      "\n",
      "üîç Token step 10\n",
      "   government: 0.6223\n",
      "   army: 0.0511\n",
      "   regime: 0.0465\n",
      "   people: 0.0362\n",
      "   civil: 0.0310\n",
      "\n",
      "üîç Token step 11\n",
      "   has: 0.3182\n",
      "   is: 0.1991\n",
      "   had: 0.0607\n",
      "   and: 0.0431\n",
      "  's: 0.0405\n",
      "\n",
      "üîç Token step 12\n",
      "   been: 0.1192\n",
      "   not: 0.0723\n",
      "   \": 0.0679\n",
      "   no: 0.0274\n",
      "   taken: 0.0250\n",
      "\n",
      "üîç Token step 13\n",
      "   \": 0.1035\n",
      "   unable: 0.0711\n",
      "   responsible: 0.0431\n",
      "   using: 0.0358\n",
      "   ÔøΩ: 0.0297\n",
      "\n",
      "üîç Token step 14\n",
      "  in: 0.0287\n",
      "  dis: 0.0278\n",
      "  completely: 0.0223\n",
      "  ab: 0.0191\n",
      "  t: 0.0174\n",
      "\n",
      "üîç Token step 15\n",
      "   the: 0.1285\n",
      "   a: 0.0830\n",
      "   constant: 0.0473\n",
      "   direct: 0.0430\n",
      "   contact: 0.0404\n",
      "\n",
      "üîç Token step 16\n",
      "   process: 0.2369\n",
      "   wrong: 0.1019\n",
      "   midst: 0.0722\n",
      "   thro: 0.0438\n",
      "   dark: 0.0331\n",
      "\n",
      "üîç Token step 17\n",
      "   of: 0.9542\n",
      "  \": 0.0327\n",
      "   and: 0.0042\n",
      "   for: 0.0010\n",
      "  ,: 0.0010\n",
      "\n",
      "üîç Token step 18\n",
      "   taking: 0.0320\n",
      "   destroying: 0.0320\n",
      "   stabil: 0.0206\n",
      "   trying: 0.0151\n",
      "   fighting: 0.0151\n",
      "\n",
      "üîç Token step 19\n",
      "   over: 0.2372\n",
      "   control: 0.1847\n",
      "   the: 0.0513\n",
      "   steps: 0.0467\n",
      "   a: 0.0342\n",
      "\n",
      "üîç Token step 20\n",
      "   the: 0.2894\n",
      "   control: 0.0503\n",
      "   large: 0.0444\n",
      "   a: 0.0404\n",
      "  \": 0.0380\n",
      "\n",
      "üìù Final generated text:\n",
      "The United Nations has issued a statement on the situation in Syria, saying that the Syrian government has been \"in the process of taking over the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_with_token_probabilities(prompt, max_tokens=20):\n",
    "    \"\"\"Generate text token by token, displaying each step with probabilities.\"\"\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    print(f\"üìù Starting prompt: {prompt}\")\n",
    "    generated_text = prompt\n",
    "\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs.logits  # Raw model outputs\n",
    "        \n",
    "        # Get probability distribution for next token\n",
    "        probs = torch.softmax(logits[0, -1, :], dim=-1)  \n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "\n",
    "        # Print top token choices\n",
    "        print(f\"\\nüîç Token step {_+1}\")\n",
    "        for i in range(5):  # Show top 5 predictions\n",
    "            token = tokenizer.decode([sorted_indices[i].item()])\n",
    "            print(f\"  {token}: {sorted_probs[i].item():.4f}\")\n",
    "\n",
    "        # Select most probable token\n",
    "        next_token_id = sorted_indices[0].item()\n",
    "        next_token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        # Append token to generated text\n",
    "        generated_text += next_token\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[next_token_id]]).to(device)], dim=1)\n",
    "\n",
    "        # Stop if end token is reached\n",
    "        if next_token == tokenizer.eos_token:\n",
    "            print(\"\\nüö´ End of text token reached.\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nüìù Final generated text:\")\n",
    "    print(generated_text)\n",
    "\n",
    "# Test the function\n",
    "generate_with_token_probabilities(\"The United Nations has issued a statement on\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef089eb8-2c9d-4933-8c83-68d81b52298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679dfdc-7afe-42ef-a236-aa2d6c893a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
