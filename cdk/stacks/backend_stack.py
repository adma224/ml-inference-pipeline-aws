from aws_cdk import (
    Stack,
    Duration,
    aws_lambda as _lambda,
    aws_iam as iam,
    aws_rds as rds,
    aws_ec2 as ec2,
    aws_ssm as ssm,
    custom_resources as cr,
    CfnResource, RemovalPolicy
)

from aws_cdk import aws_secretsmanager as secretsmanager
from aws_cdk import CfnOutput

from constructs import Construct


"""
    BackendStack
    The backend infrastructure for the microservice architecture. This stack creates:
    - VPC for the backend services
    - Aurora Serverless SQL database for saving inference prompt, responses, and user feedback
    - Lambda functions that handle different microservices such as
        - DBInitHandler: initiate a table in SQL database upon CDK stack deployment (setup)
        - PingHandler: ping the serverless Sagemaker endpoint for warming up inference container
        - GenerateHandler: serve a prompt to the inference endpoint and return the generated response and save it in the SQL database
        - VoteHandler: save user upvote or downvote as for the generated response
    - Save handler names and SQL database values in SSM or Secrets Manager

"""

class BackendStack(Stack):
    def __init__(self, scope: Construct, id: str, **kwargs):
        super().__init__(scope, id, **kwargs)


        """
        
        DATABASE DEPLOYMENT
        
        
        """

        """
        VPC for Aurora + Lambdas
        """

        vpc = ec2.Vpc(self, "BackendVpc", max_azs=2)

        """
        Create Aurora Serverless v1 cluster with autogenerated secret
        """

        # üë∑ Create DB Subnet Group from VPC
        subnet_group = rds.CfnDBSubnetGroup(self, "DBSubnetGroup",
            db_subnet_group_description="Subnets for Aurora Serverless v2",
            subnet_ids=[subnet.subnet_id for subnet in vpc.private_subnets],
            db_subnet_group_name="aurora-serverless-subnet-group"
        )

        # üîê Generate a Secrets Manager entry for DB credentials
        db_secret = secretsmanager.Secret(self, "AuroraDBSecret",
            generate_secret_string=secretsmanager.SecretStringGenerator(
                secret_string_template='{"username": "admin"}',
                generate_string_key="password",
                exclude_punctuation=True
            )
        )

        # üß† Aurora Serverless v2 cluster via low-level CfnDBCluster
        cluster = rds.CfnDBCluster(self, "AuroraV2Cluster",
            engine="aurora-postgresql",
            engine_version="13.8",
            db_subnet_group_name=subnet_group.db_subnet_group_name,
            database_name="mlpipeline",
            master_username="admin",
            master_user_password=db_secret.secret_value_from_json("password").unsafe_unwrap(),
            serverless_v2_scaling_configuration={
                "MinCapacity": 2,
                "MaxCapacity": 8
            },
            storage_encrypted=True,
            enable_http_endpoint=True,
            deletion_protection=False
        )
        cluster.add_dependency(subnet_group)  # Ensure subnet group is created first


        """

        AWS CDK BUG WHEN DEPLOYING Aurora v2 serverless cluster: The engine mode serverless you requested is currently unavailable.
        More info here: https://github.com/aws/aws-cdk/issues/20197

        cluster = rds.ServerlessCluster(self, "FeedbackDB",
            engine=rds.DatabaseClusterEngine.aurora_postgres(
                version=rds.AuroraPostgresEngineVersion.VER_13_8  # Aurora Serverless v2
            ),
            vpc=vpc,

            # Use private subnets for security
            vpc_subnets=ec2.SubnetSelection(
                subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS  # Use PRIVATE_ISOLATED if NAT is not needed
            ),

            credentials=rds.Credentials.from_generated_secret("admin"),  # Creates SecretsManager entry

            default_database_name="mlpipeline",

            # Serverless v2 scaling config
            scaling=rds.ServerlessScalingOptions(
                auto_pause=Duration.minutes(10),  # Pause when idle
                min_capacity=rds.AuroraCapacityUnit.ACU_2,     # Smallest allowed (ACU = Aurora Capacity Unit)
                max_capacity=rds.AuroraCapacityUnit.ACU_8
            ),

            enable_data_api=True,              # Required for boto3 + Lambda integration
            removal_policy=RemovalPolicy.DESTROY  # Clean up when CDK stack is destroyed (for dev only)
        )
        
        """


        """
        Common IAM policy for RDS + Secrets Manager access
        """

        rds_access_policy = iam.PolicyStatement(
            actions=["rds-data:*", "secretsmanager:GetSecretValue"],
            resources=["*"]
        )

        """
        
        LAMBDA FUNCTIONS FOR INFERENCE
        
        """


        """
        DBInitHandler: Helper lambda function that creates table inside the SQL database
        """

        db_init_fn = _lambda.Function(self, "DBInitHandler",
            runtime=_lambda.Runtime.PYTHON_3_10,
            handler="lambda_function.handler",
            code=_lambda.Code.from_asset("../lambda/db_init"),
            vpc=vpc,
            timeout=Duration.seconds(30),
            environment={
                "ENDPOINT_NAME_PARAM": endpoint_param.parameter_name,
                "CLUSTER_ARN": cluster.ref,
                "DB_SECRET_ARN": db_secret.secret_arn,
                "DB_NAME": "mlpipeline"
            }

        )
        db_init_fn.add_to_role_policy(rds_access_policy)

        """
        Trigger DBInitHandler at stack deployment
        """
        CfnResource(self, "DBInitTrigger",
            type="Custom::DBInit",
            properties={
                "ServiceToken": db_init_fn.function_arn
            }
        )


        """
        Query endpoint name parameter for SageMaker Inference
        """

        endpoint_param = ssm.StringParameter.from_string_parameter_name(
            self, "EndpointNameParam",
            string_parameter_name="/ml-pipeline/sagemaker/endpoint-name"
        )

        """
        GenerateHandler: takes prompt to inference endpoint and returns response. Logs response in SQL table
        """

        self.generate_fn = _lambda.Function(
            self, "GenerateHandler",
            runtime=_lambda.Runtime.PYTHON_3_10,
            handler="lambda_function.handler",
            code=_lambda.Code.from_asset("../lambda/generate"),
            vpc=vpc,
            environment={
                "ENDPOINT_NAME_PARAM": endpoint_param.parameter_name,
                "CLUSTER_ARN": cluster.cluster_arn,
                "DB_SECRET_ARN": cluster.secret.secret_arn,
                "DB_NAME": "mlpipeline"
            },
            timeout=Duration.seconds(30)
        )
        endpoint_param.grant_read(self.generate_fn)
        self.generate_fn.add_to_role_policy(rds_access_policy)
        self.generate_fn.add_to_role_policy(iam.PolicyStatement(
            actions=["sagemaker:InvokeEndpoint"],
            resources=["*"]
        ))

        """
        PingHandler: prompts inference endpoint to warm it up at page load
        """

        self.ping_fn = _lambda.Function(
            self, "PingHandler",
            runtime=_lambda.Runtime.PYTHON_3_10,
            handler="lambda_function.handler",
            code=_lambda.Code.from_asset("../lambda/ping"),
            vpc=vpc,
            environment={
                "ENDPOINT_NAME_PARAM": endpoint_param.parameter_name
            },
            timeout=Duration.seconds(30)
        )
        endpoint_param.grant_read(self.ping_fn)
        self.ping_fn.add_to_role_policy(iam.PolicyStatement(
            actions=["sagemaker:InvokeEndpoint"],
            resources=["*"]
        ))

        """
        VoteHandler: retreives user upvote or downvote and saves it in corresponding SQL entry
        """

        self.vote_fn = _lambda.Function(
            self, "VoteHandler",
            runtime=_lambda.Runtime.PYTHON_3_10,
            handler="lambda_function.handler",
            code=_lambda.Code.from_asset("../lambda/vote"),
            vpc=vpc,
            environment={
                "CLUSTER_ARN": cluster.cluster_arn,
                "DB_SECRET_ARN": cluster.secret.secret_arn,
                "DB_NAME": "mlpipeline"
            },
            timeout=Duration.seconds(5)
        )
        self.vote_fn.add_to_role_policy(rds_access_policy)

        """
        Saves database values in SSM for later reference
        """
        ssm.StringParameter(self, "AuroraClusterArnParam",
            parameter_name="/ml-pipeline/db/cluster-arn",
            string_value=cluster.ref
        )

        ssm.StringParameter(self, "AuroraSecretArnParam",
            parameter_name="/ml-pipeline/db/secret-arn",
            string_value=db_secret.secret_arn
        )
